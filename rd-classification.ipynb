{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1. Import Packages","metadata":{"id":"mmjokchozCgO"}},{"cell_type":"code","source":"%load_ext tensorboard\n!pip install tensorflow==2.3\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install tensorflow_addons","metadata":{"execution":{"iopub.status.busy":"2022-07-01T18:04:01.445862Z","iopub.execute_input":"2022-07-01T18:04:01.446484Z","iopub.status.idle":"2022-07-01T18:04:09.436070Z","shell.execute_reply.started":"2022-07-01T18:04:01.446437Z","shell.execute_reply":"2022-07-01T18:04:09.434767Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Requirement already satisfied: tensorflow_addons in /opt/conda/lib/python3.7/site-packages (0.12.1)\nRequirement already satisfied: typeguard>=2.7 in /opt/conda/lib/python3.7/site-packages (from tensorflow_addons) (2.12.1)\n\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install tf-nightly","metadata":{"execution":{"iopub.status.busy":"2022-07-01T17:49:23.325554Z","iopub.execute_input":"2022-07-01T17:49:23.326406Z","iopub.status.idle":"2022-07-01T17:49:32.177736Z","shell.execute_reply.started":"2022-07-01T17:49:23.326248Z","shell.execute_reply":"2022-07-01T17:49:32.176271Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: tf-nightly in /opt/conda/lib/python3.7/site-packages (2.10.0.dev20220701)\nCollecting flatbuffers>=2.0\n  Using cached flatbuffers-2.0-py2.py3-none-any.whl (26 kB)\nRequirement already satisfied: protobuf<3.20,>=3.9.2 in /opt/conda/lib/python3.7/site-packages (from tf-nightly) (3.17.3)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.7/site-packages (from tf-nightly) (14.0.1)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tf-nightly) (1.6.3)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tf-nightly) (1.15.0)\nRequirement already satisfied: keras-preprocessing>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from tf-nightly) (1.1.2)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.7/site-packages (from tf-nightly) (2.10.0)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from tf-nightly) (1.1.0)\nRequirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.7/site-packages (from tf-nightly) (1.12.1)\nRequirement already satisfied: numpy>=1.20 in /opt/conda/lib/python3.7/site-packages (from tf-nightly) (1.21.6)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.7/site-packages (from tf-nightly) (0.26.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.7/site-packages (from tf-nightly) (3.7.4.3)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from tf-nightly) (20.9)\nRequirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from tf-nightly) (0.3.3)\nRequirement already satisfied: keras-nightly~=2.10.0.dev in /opt/conda/lib/python3.7/site-packages (from tf-nightly) (2.10.0.dev2022070107)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from tf-nightly) (49.6.0.post20210108)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tf-nightly) (1.1.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.7/site-packages (from tf-nightly) (1.32.0)\nRequirement already satisfied: tf-estimator-nightly~=2.10.0.dev in /opt/conda/lib/python3.7/site-packages (from tf-nightly) (2.10.0.dev2022070108)\nRequirement already satisfied: tb-nightly~=2.10.0.a in /opt/conda/lib/python3.7/site-packages (from tf-nightly) (2.10.0a20220701)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.7/site-packages (from tf-nightly) (3.3.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.7/site-packages (from tf-nightly) (0.2.0)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.7/site-packages (from astunparse>=1.6.0->tf-nightly) (0.36.2)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tb-nightly~=2.10.0.a->tf-nightly) (1.30.2)\nRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tb-nightly~=2.10.0.a->tf-nightly) (1.8.0)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from tb-nightly~=2.10.0.a->tf-nightly) (2.0.1)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tb-nightly~=2.10.0.a->tf-nightly) (2.25.1)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tb-nightly~=2.10.0.a->tf-nightly) (3.3.4)\nRequirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tb-nightly~=2.10.0.a->tf-nightly) (0.6.1)\nRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tb-nightly~=2.10.0.a->tf-nightly) (0.4.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tb-nightly~=2.10.0.a->tf-nightly) (0.2.7)\nRequirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tb-nightly~=2.10.0.a->tf-nightly) (4.2.2)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tb-nightly~=2.10.0.a->tf-nightly) (4.7.2)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tb-nightly~=2.10.0.a->tf-nightly) (1.3.0)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tb-nightly~=2.10.0.a->tf-nightly) (3.4.0)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tb-nightly~=2.10.0.a->tf-nightly) (0.4.8)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tb-nightly~=2.10.0.a->tf-nightly) (1.26.5)\nRequirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tb-nightly~=2.10.0.a->tf-nightly) (4.0.0)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tb-nightly~=2.10.0.a->tf-nightly) (2021.5.30)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tb-nightly~=2.10.0.a->tf-nightly) (2.10)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tb-nightly~=2.10.0.a->tf-nightly) (3.1.1)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tb-nightly~=2.10.0.a->tf-nightly) (3.4.1)\nRequirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->tf-nightly) (2.4.7)\nInstalling collected packages: flatbuffers\n  Attempting uninstall: flatbuffers\n    Found existing installation: flatbuffers 1.12\n    Uninstalling flatbuffers-1.12:\n      Successfully uninstalled flatbuffers-1.12\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow 2.9.1 requires flatbuffers<2,>=1.12, but you have flatbuffers 2.0 which is incompatible.\ntensorflow-gpu 2.4.1 requires absl-py~=0.10, but you have absl-py 1.1.0 which is incompatible.\ntensorflow-gpu 2.4.1 requires flatbuffers~=1.12.0, but you have flatbuffers 2.0 which is incompatible.\ntensorflow-gpu 2.4.1 requires numpy~=1.19.2, but you have numpy 1.21.6 which is incompatible.\ntensorflow-gpu 2.4.1 requires tensorflow-estimator<2.5.0,>=2.4.0, but you have tensorflow-estimator 2.9.0 which is incompatible.\u001b[0m\nSuccessfully installed flatbuffers-2.0\n\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install --upgrade tensorflow","metadata":{"execution":{"iopub.status.busy":"2022-07-01T17:49:32.186346Z","iopub.execute_input":"2022-07-01T17:49:32.187140Z","iopub.status.idle":"2022-07-01T17:49:40.727255Z","shell.execute_reply.started":"2022-07-01T17:49:32.187086Z","shell.execute_reply":"2022-07-01T17:49:40.725546Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: tensorflow in /opt/conda/lib/python3.7/site-packages (2.9.1)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from tensorflow) (20.9)\nRequirement already satisfied: keras-preprocessing>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.1.2)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: tensorboard<2.10,>=2.9 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (2.9.1)\nRequirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (0.3.3)\nRequirement already satisfied: numpy>=1.20 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.21.6)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (3.7.4.3)\nRequirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.12.1)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.32.0)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.15.0)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (14.0.1)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.1.0)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (3.3.0)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (2.10.0)\nRequirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (2.9.0)\nCollecting flatbuffers<2,>=1.12\n  Using cached flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.1.0)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from tensorflow) (49.6.0.post20210108)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (0.26.0)\nRequirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (2.9.0)\nRequirement already satisfied: protobuf<3.20,>=3.9.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (3.17.3)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.7/site-packages (from astunparse>=1.6.0->tensorflow) (0.36.2)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.30.2)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.25.1)\nRequirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\nRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.4)\nRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.3.4)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.0.1)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.7)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.7.2)\nRequirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.2.2)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.0)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (3.4.0)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2021.5.30)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.26.5)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.10)\nRequirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (4.0.0)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.1.1)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (3.4.1)\nRequirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->tensorflow) (2.4.7)\nInstalling collected packages: flatbuffers\n  Attempting uninstall: flatbuffers\n    Found existing installation: flatbuffers 2.0\n    Uninstalling flatbuffers-2.0:\n      Successfully uninstalled flatbuffers-2.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntf-nightly 2.10.0.dev20220701 requires flatbuffers>=2.0, but you have flatbuffers 1.12 which is incompatible.\ntensorflow-gpu 2.4.1 requires absl-py~=0.10, but you have absl-py 1.1.0 which is incompatible.\ntensorflow-gpu 2.4.1 requires numpy~=1.19.2, but you have numpy 1.21.6 which is incompatible.\ntensorflow-gpu 2.4.1 requires tensorflow-estimator<2.5.0,>=2.4.0, but you have tensorflow-estimator 2.9.0 which is incompatible.\u001b[0m\nSuccessfully installed flatbuffers-1.12\n\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport tensorflow as tf\nfrom PIL import Image\nfrom matplotlib import pyplot as plt\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\nfrom tensorflow.keras.applications.resnet50 import ResNet50\nfrom tensorflow.keras.applications.vgg19 import VGG19\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.layers import Conv2D, ReLU, Dropout, MaxPooling2D\nimport tensorflow.keras.layers as tfl\nfrom tensorflow.keras.layers.experimental.preprocessing import RandomFlip, RandomRotation, RandomContrast\nfrom tensorflow.keras.utils import image_dataset_from_directory\nimport os\nimport numpy as np\nimport tensorflow_addons as tfa\nfrom datetime import datetime\nfrom tensorflow import keras\nimport sklearn\nimport tensorflow.keras.backend as kb\nimport PIL\nfrom sklearn.metrics import multilabel_confusion_matrix\nimport seaborn as sns","metadata":{"id":"gzMt0Ij_U08Y","execution":{"iopub.status.busy":"2022-07-01T17:49:44.379511Z","iopub.execute_input":"2022-07-01T17:49:44.380104Z","iopub.status.idle":"2022-07-01T17:49:48.759294Z","shell.execute_reply.started":"2022-07-01T17:49:44.380036Z","shell.execute_reply":"2022-07-01T17:49:48.758110Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/tensorflow_addons/utils/ensure_tf_install.py:67: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.3.0 and strictly below 2.5.0 (nightly versions are not supported). \n The versions of TensorFlow you are currently using is 2.9.1 and is not supported. \nSome things might work, some things might not.\nIf you were to encounter a bug, do not file an issue.\nIf you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \nYou can find the compatibility matrix in TensorFlow Addon's readme:\nhttps://github.com/tensorflow/addons\n  UserWarning,\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 2. Preprocess","metadata":{"id":"CXXMxJwqtJ4y"}},{"cell_type":"markdown","source":"# Crop and Resize","metadata":{}},{"cell_type":"code","source":"def crop_image(current_location, target_location, target_size=(224, 224)):\n  image = Image.open(current_location)\n  image_array = np.array(image)\n  min_width = np.argwhere(image_array[712, :, :]> 10)[0,0]\n  max_width = np.max(np.argwhere(image_array[712, :, :]> 10))\n  cropped_image = image_array[:, min_width:max_width, :]\n  new_image = Image.fromarray(cropped_image, 'RGB')\n  new_image = new_image.resize(target_size)\n  new_image.save(target_location)\n  return new_image","metadata":{"id":"eXqHzokB1ScH","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## iterate over dataset (run only once)","metadata":{"id":"x37hZprjtQ2e"}},{"cell_type":"code","source":"os.mkdir('/kaggle/working/Test')\nos.mkdir('/kaggle/working/Eval')\nos.mkdir('/kaggle/working/Train')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(1, 641):\n  current_location = f\"../input/retinal-disease-classification/Test_Set/Test_Set/Test/{i}.png\"\n  target_location = f\"/kaggle/working/Test/{i}.png\"\n  crop_image(current_location, target_location)\nprint('done!')\nfor i in range(1, 641):\n  current_location = f\"../input/retinal-disease-classification/Evaluation_Set/Evaluation_Set/Validation/{i}.png\"\n  target_location = f\"/kaggle/working/Eval/{i}.png\"\n  crop_image(current_location, target_location)\nprint('done!')\nfor i in range(1, 1921):\n  current_location = f\"../input/retinal-disease-classification/Training_Set/Training_Set/Training/{i}.png\"\n  target_location = f\"/kaggle/working/Train/{i}.png\"\n  crop_image(current_location, target_location)\nprint('done!')","metadata":{"id":"h4oqPhh4Nf-F","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. create labels","metadata":{"id":"SUf8pMQ_l1i2"}},{"cell_type":"code","source":"def create_labels(csv_path : str, class_names):\n\n  dataframe = pd.read_csv(csv_path)\n  dataframe = dataframe[class_names]\n\n  return dataframe.to_numpy()","metadata":{"id":"l8BJH-RYln3v","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_names = ['DR']\ntraining_labels = create_labels('../input/retinal-disease-classification/Training_Set/Training_Set/RFMiD_Training_Labels.csv', class_names)\ntest_labels = create_labels('../input/retinal-disease-classification/Test_Set/Test_Set/RFMiD_Testing_Labels.csv', class_names)\nvalidation_labels = create_labels('../input/retinal-disease-classification/Evaluation_Set/Evaluation_Set/RFMiD_Validation_Labels.csv', class_names)","metadata":{"id":"7pBIEVJOpxuB","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.hist(training_labels.sum(axis=1), align='left', bins=[-1, 0, 1, 2, 3, 4, 5], rwidth=0.25)","metadata":{"id":"mzzMFZoXF-MZ","outputId":"7af7b575-5bd4-4f18-a201-9b0a236e5e6f","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for y in [training_labels, validation_labels]:\n  total = y.sum()\n  total_labels = y.sum(axis=0)\n  fractions = total_labels/total\n  weights = 1/fractions","metadata":{"id":"uumyCvGRRJf5","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. load data","metadata":{"id":"6tCsn2lKnk6e"}},{"cell_type":"code","source":"def parse_function(filename : str, label, channels=3):\n\n    image_string = tf.io.read_file(filename)\n    image_decoded = tf.image.decode_png(image_string, channels=channels)\n    image_normalized = tf.cast(image_decoded, tf.float32) / 255.0\n\n    return image_normalized, label","metadata":{"id":"CSyFQv3SrCz2","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 8\nsbf = 512\nAUTOTUNE = tf.data.experimental.AUTOTUNE","metadata":{"id":"VmnBMu2wsxFt","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_dataset(filenames, labels, is_training=True):\n\n    dir_list = os.listdir(filenames)\n    new_dir_list = [ filenames + k for k in dir_list]\n    dataset = tf.data.Dataset.from_tensor_slices((new_dir_list, labels))\n    dataset = dataset.map(lambda x, y: parse_function(x, y), num_parallel_calls=AUTOTUNE)\n        \n    if is_training == True:\n        dataset = dataset.cache()\n        dataset = dataset.shuffle(buffer_size=sbf)\n    \n    dataset = dataset.batch(batch_size)\n    dataset = dataset.prefetch(buffer_size=AUTOTUNE)\n    \n    return dataset","metadata":{"id":"r-12SYJPrxF6","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_dataset = create_dataset('../input/retianaldiseasespreprocessed/Train/', training_labels)\nvalidation_dataset = create_dataset('../input/retianaldiseasespreprocessed/Eval/', validation_labels)\ntest_dataset = create_dataset('../input/retianaldiseasespreprocessed/Test/', test_labels, is_training=False)","metadata":{"id":"eUm2FLvRtqTI","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##run for new datset","metadata":{}},{"cell_type":"code","source":"BATCH_SIZE = 32\nIMG_SIZE = (224, 224)\ndirectory = \"../input/diabetic-retinopathy-preprocessed-dataset/Dataset/\"\ntrain_dataset = image_dataset_from_directory(directory,\n                                             shuffle=True,\n                                             batch_size=BATCH_SIZE,\n                                             image_size=IMG_SIZE,\n                                             validation_split=0.2,\n                                             subset='training',\n                                             label_mode='categorical',\n                                             seed=42)\nvalidation_dataset = image_dataset_from_directory(directory,\n                                             shuffle=True,\n                                             batch_size=BATCH_SIZE,\n                                             image_size=IMG_SIZE,\n                                             validation_split=0.2,\n                                             subset='validation',\n                                             label_mode='categorical',\n                                             seed=42)","metadata":{"execution":{"iopub.status.busy":"2022-07-01T18:34:01.627850Z","iopub.execute_input":"2022-07-01T18:34:01.628246Z","iopub.status.idle":"2022-07-01T18:34:09.569424Z","shell.execute_reply.started":"2022-07-01T18:34:01.628198Z","shell.execute_reply":"2022-07-01T18:34:09.568105Z"},"trusted":true},"execution_count":63,"outputs":[{"name":"stdout","text":"Found 13970 files belonging to 5 classes.\nUsing 11176 files for training.\nFound 13970 files belonging to 5 classes.\nUsing 2794 files for validation.\n","output_type":"stream"}]},{"cell_type":"code","source":"for image, label in train_dataset.take(1):\n    print(label)","metadata":{"execution":{"iopub.status.busy":"2022-07-01T18:34:09.571451Z","iopub.execute_input":"2022-07-01T18:34:09.572176Z","iopub.status.idle":"2022-07-01T18:34:09.888780Z","shell.execute_reply.started":"2022-07-01T18:34:09.572129Z","shell.execute_reply":"2022-07-01T18:34:09.887689Z"},"trusted":true},"execution_count":64,"outputs":[{"name":"stdout","text":"tf.Tensor(\n[[1. 0. 0. 0. 0.]\n [0. 0. 0. 0. 1.]\n [0. 0. 0. 0. 1.]\n [0. 0. 1. 0. 0.]\n [0. 1. 0. 0. 0.]\n [0. 0. 1. 0. 0.]\n [0. 0. 1. 0. 0.]\n [0. 0. 1. 0. 0.]\n [0. 0. 1. 0. 0.]\n [0. 0. 0. 1. 0.]\n [0. 0. 1. 0. 0.]\n [0. 0. 1. 0. 0.]\n [0. 0. 1. 0. 0.]\n [0. 0. 1. 0. 0.]\n [0. 0. 1. 0. 0.]\n [0. 0. 1. 0. 0.]\n [0. 0. 1. 0. 0.]\n [0. 0. 1. 0. 0.]\n [0. 1. 0. 0. 0.]\n [0. 0. 0. 0. 1.]\n [0. 1. 0. 0. 0.]\n [0. 0. 1. 0. 0.]\n [0. 1. 0. 0. 0.]\n [0. 1. 0. 0. 0.]\n [0. 1. 0. 0. 0.]\n [0. 0. 1. 0. 0.]\n [0. 0. 1. 0. 0.]\n [0. 0. 1. 0. 0.]\n [0. 0. 1. 0. 0.]\n [0. 1. 0. 0. 0.]\n [0. 0. 1. 0. 0.]\n [0. 0. 1. 0. 0.]], shape=(32, 5), dtype=float32)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 5. Augmentation","metadata":{"id":"1zPGI7zxifGQ"}},{"cell_type":"code","source":"def data_augmenter():\n\n    data_augmentation = tf.keras.Sequential()\n    data_augmentation.add(RandomRotation(0.4, fill_mode='constant')) \n    data_augmentation.add(RandomFlip())\n    data_augmentation.add(RandomContrast(0.3))\n\n    return data_augmentation","metadata":{"id":"bMu5WuqLikPS","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"data_augmentation = data_augmenter()\ndef prepare(ds, shuffle=False, augment=False):\n  if augment:\n    ds = ds.map(lambda x, y: (data_augmentation(x), y), \n                num_parallel_calls=AUTOTUNE)\n\n  return ds.prefetch(buffer_size=AUTOTUNE)\"\"\"","metadata":{"id":"CBSkPvHTJ_Qq","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_augmentation = data_augmenter()\ndef prepare(ds, augment=False):\n  if augment:\n    #ds = ds.map(if_ds, num_parallel_calls=AUTOTUNE)\n    labels = []\n    images = []\n    for x, y in ds:\n      for k in range(batch_size):\n        if y[k] == 1:\n            labels.append(y[k])\n            images.append(data_augmentation(tf.expand_dims(x[k], 0))[0])\n    ds = tf.data.Dataset.from_tensor_slices((images, labels)) \n    ds = ds.batch(batch_size)\n       \n  return ds.prefetch(buffer_size=AUTOTUNE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_training_dataset = training_dataset\nfor i in range(3): \n  train_ds = prepare(training_dataset, augment=True)\n  new_training_dataset = new_training_dataset.concatenate(train_ds)\nnew_training_dataset = new_training_dataset.shuffle(buffer_size=sbf)\nnew_training_dataset","metadata":{"id":"Zu48xNV8KngI","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_augmentation = data_augmenter()\n\nfor image, _ in training_dataset.take(1):\n    plt.figure(figsize=(10, 10))\n    \n    first_image = image[0]\n    #print(first_image.shape)\n    plt.subplot(3, 3, 1)\n    plt.imshow(first_image)\n    for i in range(8):\n        plt.subplot(3, 3, i + 2)\n        augmented_image = data_augmentation(tf.expand_dims(first_image, 0))\n        plt.imshow(augmented_image[0])\n        plt.axis('off')","metadata":{"id":"jnXzZZKOkLpW","outputId":"d6519aab-4462-4d4e-d2ce-c2ec2ac5a869","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_training_labels = []\n\nfor image, labels in new_training_dataset:\n    for label in labels:\n        new_training_labels.append(int(label))\nplt.hist(new_training_labels, align='left', bins=[-1, 0, 1, 2, 3, 4, 5], rwidth=0.25)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6. Confusion Matrix","metadata":{"id":"xxtRwCyiNZ9H"}},{"cell_type":"code","source":"def plot_confusion_matrix(cm, class_names):\n    \"\"\"\n    Returns a matplotlib figure containing the plotted confusion matrix.\n    \n    Args:\n       cm (array, shape = [n, n]): a confusion matrix of integer classes\n       class_names (array, shape = [n]): String names of the integer classes\n    \"\"\"\n    \n    figure = plt.figure(figsize=(8, 8))\n    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n    plt.title(\"Confusion matrix\")\n    plt.colorbar()\n    tick_marks = np.arange(len(class_names))\n    plt.xticks(tick_marks, class_names, rotation=45)\n    plt.yticks(tick_marks, class_names)\n    \n    # Normalize the confusion matrix.\n    cm = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n    \n    # Use white text if squares are dark; otherwise black.\n    threshold = cm.max() / 2.\n    \n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        color = \"white\" if cm[i, j] > threshold else \"black\"\n        plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=color)\n        \n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    return figure","metadata":{"id":"xJlmOvqV9tBV","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"logdir = \"/content/drive/MyDrive/Colab Notebooks/logs/image/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\ntensorboard_callback = keras.callbacks.TensorBoard(log_dir = logdir, histogram_freq = 1)\nfile_writer_cm = tf.summary.create_file_writer(logdir + '/cm')","metadata":{"id":"eMta6-92OcMl","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_to_image(figure):\n    \"\"\"\n    Converts the matplotlib plot specified by 'figure' to a PNG image and\n    returns it. The supplied figure is closed and inaccessible after this call.\n    \"\"\"\n    \n    buf = io.BytesIO()\n    \n    # Use plt.savefig to save the plot to a PNG in memory.\n    plt.savefig(buf, format='png')\n    \n    # Closing the figure prevents it from being displayed directly inside\n    # the notebook.\n    plt.close(figure)\n    buf.seek(0)\n    \n    # Use tf.image.decode_png to convert the PNG buffer\n    # to a TF image. Make sure you use 4 channels.\n    image = tf.image.decode_png(buf.getvalue(), channels=4)\n    \n    # Use tf.expand_dims to add the batch dimension\n    image = tf.expand_dims(image, 0)\n    \n    return image","metadata":{"id":"s7K6j9CyOGSt","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def log_confusion_matrix(epoch, logs):\n    \n    # Use the model to predict the values from the test_images.\n    test_pred_raw = model.predict(test_dataset)\n    \n    test_pred = np.argmax(test_pred_raw, axis=1)\n    \n    # Calculate the confusion matrix using sklearn.metrics\n    cm = sklearn.metrics.confusion_matrix(test_labels, test_pred)\n    \n    figure = plot_confusion_matrix(cm, class_names=class_names)\n    cm_image = plot_to_image(figure)\n    \n    # Log the confusion matrix as an image summary.\n    with file_writer_cm.as_default():\n        tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)","metadata":{"id":"PaFnuRw0J2VD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 7. Training","metadata":{"id":"qhTVxvGJ7Hox"}},{"cell_type":"code","source":"def block_inc(inputs):\n  x1 = tfl.Conv2D(128, (1, 1), padding='same')(inputs)\n  x1 = tfl.Conv2D(128, (3, 3), padding='same')(x1)\n  x2 = tfl.Conv2D(64, (1, 1), padding='same')(inputs)\n  x2 = tfl.Conv2D(64, (5, 5), padding='same')(x2)\n  x3 = tfl.Conv2D(128, (1, 1), padding='same')(inputs)\n  x3 = tfl.Conv2D(32, (7, 7), padding='same')(x3)\n  x4 = tfl.MaxPool2D(strides=1, padding='same')(inputs)\n  x = tfl.Concatenate()([x1, x2, x3, x4])\n  x = tfl.MaxPool2D()(x)\n  return x","metadata":{"execution":{"iopub.status.busy":"2022-07-01T18:34:18.480115Z","iopub.execute_input":"2022-07-01T18:34:18.480486Z","iopub.status.idle":"2022-07-01T18:34:18.489310Z","shell.execute_reply.started":"2022-07-01T18:34:18.480455Z","shell.execute_reply":"2022-07-01T18:34:18.487686Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"def classification(pre_trained_model_name : str, input_shape: tuple =(224, 224, 3), scratch = True):\n  \n  if pre_trained_model_name == 'inception':\n    pre_trained_model = InceptionV3(input_shape=input_shape, include_top=False, weights=None)\n  \n  elif pre_trained_model_name == 'resnet':\n    pre_trained_model = ResNet50(input_shape=input_shape, include_top=False, weights=None)\n  \n  elif pre_trained_model_name == 'vgg':\n    pre_trained_model = VGG19(input_shape=input_shape, include_top=False, weights=None)\n\n  if scratch == False:\n    for layer in pre_trained_model.layers:\n      layer.trainable = False\n  inputs = tf.keras.Input(shape=input_shape, name='Input')\n  #x = block_inc(inputs)\n  #x = block_inc(x)\n  #x = block_inc(x)\n  #x = block_inc(x)\n  x = pre_trained_model(inputs)\n  x = tfl.Flatten(name='Flatten')(x)\n  x = tfl.Dense(64, activation='relu', name='1st_Fully_Connected')(x)\n  x = tfl.Dense(32, activation='relu', name='2nd_Fully_Connected')(x)\n  #x = tfl.Dropout(0.2)(x)\n  x = tfl.Dense(5, activation='softmax', name='Output')(x)\n  model = tf.keras.Model(inputs=inputs, outputs=x, name=f'Transfer_Learning_by_{pre_trained_model_name}')\n  \n  return model\n","metadata":{"id":"kG8nFG5ktKw5","execution":{"iopub.status.busy":"2022-07-01T18:34:18.642875Z","iopub.execute_input":"2022-07-01T18:34:18.643261Z","iopub.status.idle":"2022-07-01T18:34:18.655271Z","shell.execute_reply.started":"2022-07-01T18:34:18.643229Z","shell.execute_reply":"2022-07-01T18:34:18.653783Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"model = classification('resnet')\nmodel.summary()","metadata":{"id":"CkKMqZlQWNa8","outputId":"8c73bb89-b406-4382-c0e7-c998d35fb483","execution":{"iopub.status.busy":"2022-07-01T18:34:20.066225Z","iopub.execute_input":"2022-07-01T18:34:20.066655Z","iopub.status.idle":"2022-07-01T18:34:22.242927Z","shell.execute_reply.started":"2022-07-01T18:34:20.066613Z","shell.execute_reply":"2022-07-01T18:34:22.241591Z"},"trusted":true},"execution_count":67,"outputs":[{"name":"stdout","text":"Model: \"Transfer_Learning_by_resnet\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n Input (InputLayer)          [(None, 224, 224, 3)]     0         \n                                                                 \n resnet50 (Functional)       (None, 7, 7, 2048)        23587712  \n                                                                 \n Flatten (Flatten)           (None, 100352)            0         \n                                                                 \n 1st_Fully_Connected (Dense)  (None, 64)               6422592   \n                                                                 \n 2nd_Fully_Connected (Dense)  (None, 32)               2080      \n                                                                 \n Output (Dense)              (None, 5)                 165       \n                                                                 \n=================================================================\nTotal params: 30,012,549\nTrainable params: 29,959,429\nNon-trainable params: 53,120\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"def my_loss(y_true, y_pred):\n  cost = tf.reduce_mean(kb.square(kb.dot(y_true, y_pred)))\n  return cost","metadata":{"id":"78syR61Sw0oK","execution":{"iopub.status.busy":"2022-07-01T18:34:22.245093Z","iopub.execute_input":"2022-07-01T18:34:22.245815Z","iopub.status.idle":"2022-07-01T18:34:22.252711Z","shell.execute_reply.started":"2022-07-01T18:34:22.245766Z","shell.execute_reply":"2022-07-01T18:34:22.251259Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"base_learning_rate = 0.01\nmodel.compile(optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate),\n              loss=tf.keras.losses.CategoricalCrossentropy(),\n              metrics=['accuracy', tfa.metrics.F1Score(5, average='macro', threshold=0.5, name='F1 Score')])","metadata":{"id":"z2y0bB8bNZhk","outputId":"3253f49e-4d3b-47d6-83ac-e934d024862f","execution":{"iopub.status.busy":"2022-07-01T18:34:38.469637Z","iopub.execute_input":"2022-07-01T18:34:38.470102Z","iopub.status.idle":"2022-07-01T18:34:38.495564Z","shell.execute_reply.started":"2022-07-01T18:34:38.470055Z","shell.execute_reply":"2022-07-01T18:34:38.494579Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"#callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=2)","metadata":{"id":"fDhoOW9J-2N-","execution":{"iopub.status.busy":"2022-07-01T18:34:40.240085Z","iopub.execute_input":"2022-07-01T18:34:40.240521Z","iopub.status.idle":"2022-07-01T18:34:40.245409Z","shell.execute_reply.started":"2022-07-01T18:34:40.240469Z","shell.execute_reply":"2022-07-01T18:34:40.244241Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"#cm_callback = keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)","metadata":{"id":"jt1MThxyPIJ9","execution":{"iopub.status.busy":"2022-07-01T18:34:40.408089Z","iopub.execute_input":"2022-07-01T18:34:40.408426Z","iopub.status.idle":"2022-07-01T18:34:40.413616Z","shell.execute_reply.started":"2022-07-01T18:34:40.408396Z","shell.execute_reply":"2022-07-01T18:34:40.411762Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"#%tensorboard --logdir \"/content/drive/MyDrive/Colab Notebooks/logs/image\"\nhistory = model.fit(train_dataset, validation_data=validation_dataset, epochs=5)# callbacks=[tensorboard_callback, cm_callback])#, callbacks=[callback])","metadata":{"id":"5janpEwSWPWU","outputId":"61dd28d4-13de-446f-cd88-afb9aaadd74d","execution":{"iopub.status.busy":"2022-07-01T18:34:41.026848Z","iopub.execute_input":"2022-07-01T18:34:41.027252Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/5\n 28/350 [=>............................] - ETA: 2:08:14 - loss: 54.7628 - accuracy: 0.3438 - F1 Score: 0.1369","output_type":"stream"}]},{"cell_type":"code","source":"acc = [0.] + history.history['binary_accuracy']\nval_acc = [0.] + history.history['val_binary_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nf1 = history.history['F1 Score']\nf1_val = history.history['val_F1 Score']\n\nplt.figure(figsize=(10, 10))\nplt.subplot(3, 1, 1)\nplt.plot(acc, label='Training Accuracy')\nplt.plot(val_acc, label='Validation Accuracy')\nplt.legend(loc='upper right')\nplt.ylabel('Accuracy')\nplt.ylim([min(plt.ylim()),1])\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(3, 1, 2)\nplt.plot(loss, label='Training Loss')\nplt.plot(val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.ylabel('Cross Entropy Loss')\nplt.ylim([0,1.0])\nplt.title('Training and Validation Loss')\n\n\nplt.subplot(3, 1, 3)\nplt.plot(f1, label='Training F1 Score')\nplt.plot(f1_val, label='Validation F1 Score')\nplt.legend(loc='upper right')\nplt.ylabel('F1 Score')\n#plt.ylim([min(plt.ylim()),1])\nplt.title('Training and Validation F1 Score')\nplt.xlabel('epoch')\nplt.show()","metadata":{"id":"riMUoBQBp3OK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_preds = model.predict(test_dataset, batch_size=128)","metadata":{"id":"-4rY-6_1qiIW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def _get_streaming_metrics(prediction,label,num_classes):\n\n    with tf.name_scope(\"test\"):\n        # the streaming accuracy (lookup and update tensors)\n        accuracy,accuracy_update = tf.metrics.accuracy(label, prediction, \n                                               name='accuracy')\n        # Compute a per-batch confusion\n        batch_confusion = tf.confusion_matrix(label, prediction,\n                                             num_classes=num_classes,\n                                             name='batch_confusion')\n        # Create an accumulator variable to hold the counts\n        confusion = tf.Variable( tf.zeros([num_classes,num_classes], \n                                          dtype=tf.int32 ),\n                                 name='confusion' )\n        # Create the update op for doing a \"+=\" accumulation on the batch\n        confusion_update = confusion.assign( confusion + batch_confusion )\n        # Cast counts to float so tf.summary.image renormalizes to [0,255]\n        confusion_image = tf.reshape( tf.cast( confusion, tf.float32),\n                                  [1, num_classes, num_classes, 1])\n        # Combine streaming accuracy and confusion matrix updates in one op\n        test_op = tf.group(accuracy_update, confusion_update)\n\n        tf.summary.image('confusion',confusion_image)\n        tf.summary.scalar('accuracy',accuracy)\n\n    return test_op,accuracy,confusion","metadata":{"id":"UbQbDGNEr3Jc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_preds = test_preds > 0.5\ncm = multilabel_confusion_matrix(test_labels, test_preds)","metadata":{"id":"yeqonAR1suog"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for num in range(7):\n  df_cm = pd.DataFrame(cm[num], index =['Positive', 'Negative'] ,\n                    columns = ['Positive', 'Negative'])\n  plt.figure(figsize = (40, 40))\n  plt.subplot(4, 4, num + 1)\n  sns.heatmap(df_cm, annot=True)","metadata":{"id":"vSV3O1EgtEqx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_preds","metadata":{"id":"sX52R6aTzUKo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"d4d4lMHGCCEl"},"execution_count":null,"outputs":[]}]}